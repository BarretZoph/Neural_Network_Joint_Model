{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NNJM\n",
    "#TODO\n",
    "# 1. Check to be sure slices are being done correctly\n",
    "# 2. Put in dropout\n",
    "# 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import statements\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameters for the model\n",
    "params = {}\n",
    "params['minibatch'] = 50\n",
    "params['emb-size'] = 200\n",
    "params['hiddenstate-size'] = 512\n",
    "params['source-vocab'] = 500\n",
    "params['target-vocab'] = 600\n",
    "params['datatype'] = tf.float32\n",
    "params['init-method'] = 'uniform'\n",
    "params['init-range'] = 0.01\n",
    "params['source-window'] = 11\n",
    "params['target-window'] = 4\n",
    "params['use-char'] = False\n",
    "params['seed'] = 1\n",
    "params['dropout-rate'] = 0.0\n",
    "params['loss'] = 'MLE' #('MLE','NCE','IS')\n",
    "params['learning-rate'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Interactive session\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Process the data, get the source-vocab and target-vocab variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Place holders for input and output data, first index is the minibatch size\n",
    "\n",
    "#For the input the second dimension will be passed a\n",
    "#     vector of size minibatch x (params['source-window']+params['target-window'])\n",
    "input_indices = tf.placeholder(tf.int32, shape=[None, params['source-window']+params['target-window']])\n",
    "\n",
    "#The output will be given a minibatch vector of correct indicies\n",
    "correct_output = tf.placeholder(tf.int32,shape=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def param_init(params,shape=None,name=None,datatype=None):\n",
    "    if datatype == None:\n",
    "        datatype = params['datatype']\n",
    "    assert shape != None,\"Error shape cannot be None in param_init\"\n",
    "    if params['init-method'] == 'uniform':\n",
    "        return tf.random_uniform(shape, minval=-1*params['init-range'],maxval=params['init-range'],\\\n",
    "                    dtype=datatype, seed=params['seed'], name=name)\n",
    "    else:\n",
    "        print \"ERROR this init-method has not been created yet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Parameters for the source and target embeddings\n",
    "source_emb_matrix = tf.Variable(param_init(params,shape=[params['source-vocab'],params['emb-size']],name='src-emb'))\n",
    "target_emb_matrix = tf.Variable(param_init(params,shape=[params['target-vocab'],params['emb-size']],name='tgt-emb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Do the one-hot emebedding lookups\n",
    "src_embed = tf.nn.embedding_lookup(source_emb_matrix, tf.slice(input_indices,[0,0],[-1,params['source-window']]))\n",
    "tgt_embed = tf.nn.embedding_lookup(target_emb_matrix, tf.slice(input_indices,[0,params['source-window']],\\\n",
    "                                                                [-1,params['target-window']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Tensor.get_shape of <tf.Tensor 'embedding_lookup:0' shape=(?, 11, 200) dtype=float32>>\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'embedding_lookup_1:0' shape=(?, 4, 200) dtype=float32>>\n",
      "Tensor(\"concat:0\", shape=(?, 15, 200), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(?, 3000), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Now reshape to be able to feed through non-linearity\n",
    "print src_embed.get_shape\n",
    "print tgt_embed.get_shape\n",
    "concat_embed = tf.concat(1, [src_embed, tgt_embed])\n",
    "print concat_embed\n",
    "concat_embed = tf.reshape(concat_embed,[-1,params['emb-size']*(params['source-window']+params['target-window'])])\n",
    "print concat_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Tensor.get_shape of <tf.Tensor 'Relu_1:0' shape=(?, 512) dtype=float32>>\n"
     ]
    }
   ],
   "source": [
    "#First Layer\n",
    "layer_1_weights = tf.Variable(param_init(params,\\\n",
    "    shape=[params['emb-size']*(params['source-window']+params['target-window']),params['hiddenstate-size']],name='lyr-1'))\n",
    "layer_1_bias = tf.Variable(param_init(params,shape=[params['hiddenstate-size']],name='lyr-1-bias'))\n",
    "layer_1_output = tf.nn.relu(tf.matmul(concat_embed,layer_1_weights)+layer_1_bias)\n",
    "print layer_1_output.get_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Second layer\n",
    "layer_2_weights = tf.Variable(param_init(params,shape=[params['hiddenstate-size'],params['hiddenstate-size']],\\\n",
    "                        name='lyr-2'))\n",
    "layer_2_bias = tf.Variable(param_init(params,shape=[params['hiddenstate-size']],name='lyr-2-bias'))\n",
    "layer_2_output = tf.nn.relu(tf.matmul(layer_1_output,layer_2_weights)+layer_2_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Tensor.get_shape of <tf.Tensor 'Softmax_1:0' shape=(?, 600) dtype=float32>>\n"
     ]
    }
   ],
   "source": [
    "#Softmax layer\n",
    "softmax_weights = tf.Variable(param_init(params,shape=[params['hiddenstate-size'],params['target-vocab']],\\\n",
    "                              name='softmax-weights')) \n",
    "softmax_bias = tf.Variable(param_init(params,shape=[params['target-vocab']],name='softmax-bias'))\n",
    "final_output = tf.nn.softmax(tf.matmul(layer_2_output, softmax_weights) + softmax_bias)\n",
    "loss = #use embedding lookup to \n",
    "tf.nn.embedding_lookup(, tf.slice(input_indices,[0,0],[-1,params['source-window']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
